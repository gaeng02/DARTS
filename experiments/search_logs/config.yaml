arch_learning_rate: 0.0003
arch_weight_decay: 0.001
batch_size: 64
cutout_length: 16
epochs: 50
grad_clip: 5
init_channels: 16
layers: 8
learning_rate: 0.025
learning_rate_min: 0.001
momentum: 0.9
nodes: 4
report_freq_hessian: 2.0
train_portion: 0.5
unrolled: true
